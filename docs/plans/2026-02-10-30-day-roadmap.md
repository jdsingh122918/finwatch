# FinWatch 30-Day Improvement Roadmap

**Created:** 2026-02-10
**Status:** Planning
**Scope:** Foundation fixes, intelligence upgrades, trading UI, charting

---

## Overview

Four-week plan covering critical fixes, LLM optimization, sidecar reliability, security hardening, intelligence improvements, and new frontend features.

| Week | Theme | Tasks | Est. Hours |
|------|-------|-------|------------|
| 1 | Foundation & Quick Wins | 8 tasks | 15h |
| 2 | Sidecar Reliability + Security | 4 tasks | 29h |
| 3 | Intelligence Leap | 4 tasks | 32h |
| 4 | Trading Hub + Charting | 4 tasks | 12h |
| **Total** | | **20 tasks** | **~88h** |

---

## Week 1: Foundation & Quick Wins (~15 hours)

### Task 1.1: Fix Mutex `.unwrap()` Panics (1.5h)

**Files:** `src-tauri/src/bridge.rs`

Replace 6 `.unwrap()` calls on Mutex locks (lines 63, 64, 133, 157, 165) with proper error handling to prevent app-crashing panics on mutex poisoning.

**Pattern:**
```rust
fn lock_stdin(&self) -> Result<MutexGuard<Option<ChildStdin>>, String> {
    self.stdin_writer.lock().map_err(|e| format!("stdin lock poisoned: {}", e))
}
```

**Tests:** Add `test_mutex_poisoning_recovery` to existing bridge tests.

---

### Task 1.2: Enable CSP in Tauri Config (0.5h)

**Files:** `src-tauri/tauri.conf.json`

Replace `"csp": null` (line 21) with:
```json
"csp": "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; connect-src 'self' https://api.anthropic.com https://openrouter.ai https://data.alpaca.markets"
```

**Tests:** Manual — verify all pages load, API calls work, no CSP violations in console.

---

### Task 1.3: Add Structured Logging with `tracing` Crate (2h)

**Files:** `src-tauri/Cargo.toml`, `src-tauri/src/lib.rs`, `src-tauri/src/bridge.rs`, `src-tauri/src/commands/*.rs`

**Steps:**
1. Add `tracing = "0.1"` and `tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt"] }` to Cargo.toml
2. Initialize subscriber in `lib.rs::run()` with `EnvFilter`
3. Replace all `eprintln!` (22 occurrences) with `tracing::info!`, `tracing::warn!`, `tracing::error!`
4. Add `#[tracing::instrument]` to key functions (`spawn`, `send_request`, `kill`, command handlers)

**Tests:** Run with `RUST_LOG=debug pnpm dev` and verify structured output.

---

### Task 1.4: Anthropic Prompt Caching (2.5h)

**Files:** `shared/src/provider.ts`, `agent/src/providers/anthropic-provider.ts`

**Steps:**
1. Update `CreateMessageParams.system` to accept `string | Array<{ type: "text"; text: string; cache_control?: { type: "ephemeral" } }>`
2. Update Anthropic provider to pass array system prompts directly to SDK
3. Track cache stats from `message_start` event (`cache_creation_input_tokens`, `cache_read_input_tokens`)
4. Add `cacheCreation` and `cacheRead` fields to `StreamEvent` usage event

**Impact:** ~90% cost reduction on repeated analysis cycles (system prompt cached for 5 min).

**Tests:** Mock SDK to return cache stats, verify events propagated.

---

### Task 1.5: Structured JSON Output Mode (3h)

**Files:** `shared/src/provider.ts`, `agent/src/providers/anthropic-provider.ts`, `agent/src/providers/openrouter-provider.ts`, `agent/src/analysis/response-parser.ts`, `agent/src/analysis/prompt-builder.ts`

**Steps:**
1. Add `responseFormat?: { type: "json_object"; schema?: Record<string, unknown> }` to `CreateMessageParams`
2. Anthropic: append JSON instruction to system prompt (no native JSON mode)
3. OpenRouter: use native `response_format: { type: "json_object" }` field
4. Export `ANOMALY_SCHEMA` from response-parser, add `strictJson` mode
5. Update prompt-builder to set `responseFormat` by default

**Impact:** Eliminate JSON parse failures from malformed LLM responses.

**Tests:** Verify JSON instruction appended, schema passed to OpenRouter, strict parsing mode.

---

### Task 1.6: Anomaly Feed Filters (2h)

**Files:** `src/pages/AnomalyFeed.tsx`

**Steps:**
1. Add local state: `severityFilter: Severity[]`, `symbolFilter: string`, `timeRange: number`
2. Add filter bar UI: severity toggle buttons (color-coded), symbol text input, time range dropdown
3. Use `useMemo` to filter anomalies array
4. Show count: "Anomaly Feed (N / M)"
5. Show "No anomalies match filters" vs "No anomalies detected" for empty states

**Styling:** Use existing theme tokens (`severity-*`, `border-border`, `bg-bg-surface`).

**Tests:** Filter by severity, symbol search, time range filtering.

---

### Task 1.7: Toast Notifications (2h)

**New files:** `src/components/Toast.tsx`
**Files:** `src/pages/Settings.tsx`, `src/App.tsx`, `src/index.css`

**Steps:**
1. Create custom toast system: `showToast(message, type, duration)` with listener pattern
2. `ToastContainer` component with slide-in animation, severity colors
3. Add `animate-slide-in` keyframes to index.css
4. Mount `<ToastContainer />` in App.tsx
5. Wrap Settings save callbacks in try/catch, call `showToast()` on success/error

**Tests:** showToast shows message, auto-dismiss after duration, multiple simultaneous toasts.

---

### Task 1.8: Dashboard Number Formatting (1.5h)

**New files:** `src/utils/format.ts`
**Files:** `src/pages/Dashboard.tsx`

**Steps:**
1. Create utilities: `formatPrice(n)` → "123.46", `formatVolume(n)` → "1.5M", `formatChange(n)` → "+2.50%", `getChangeColor(n)` → Tailwind class
2. Apply to Dashboard metric display: detect key names (price/close/bid/ask → formatPrice, volume → formatVolume, change_pct → formatChange with color)
3. Add directional arrows: ↑/↓/→ for positive/negative/zero

**Tests:** Unit tests for all format functions, component test for formatted rendering.

---

### Week 1 Implementation Order
1. Task 1.1 (Mutex) → prevents panics
2. Task 1.2 (CSP) → security quick win
3. Task 1.3 (Tracing) → observability for debugging
4. Task 1.8 (Formatting) → visible UI win
5. Task 1.7 (Toasts) → UI polish
6. Task 1.6 (Filters) → UI feature
7. Task 1.4 (Prompt caching) → LLM optimization
8. Task 1.5 (Structured output) → LLM reliability

---

## Week 2: Sidecar Reliability + Security (~29 hours)

### Task 2.1: Real JSON-RPC Response Handling (8h)

**New files:** `src-tauri/src/bridge_pending.rs`
**Files:** `src-tauri/src/bridge.rs`, `src-tauri/src/jsonrpc.rs`

Currently `send_request()` returns a synthetic success immediately (bridge.rs:145). Replace with real request/response tracking.

**Steps:**
1. Create `PendingRequestTracker` with `HashMap<u64, PendingRequest>` (guarded by Mutex)
   - `register(id, timeout) → Receiver<Result<JsonRpcResponse, String>>`
   - `resolve(id, response) → bool`
   - `check_timeouts()` — scan and fail expired requests
2. Add `pending: Arc<PendingRequestTracker>` to `SidecarBridge`
3. Update `send_request()`: register pending → write to stdin → drop lock → `recv_timeout(31s)`
4. Update stdout reader thread: if response has `id`, call `pending.resolve(id, response)` instead of ignoring
5. Spawn timeout checker thread: every 5s, call `check_timeouts()`
6. Clean up pending requests in `kill()` method

**Tests:** register+resolve channel, timeout fires on expired, unknown ID returns false.

---

### Task 2.2: Auto-Restart Watchdog Thread (10h)

**Files:** `src-tauri/src/bridge.rs`, `src-tauri/src/sidecar.rs`

**Steps:**
1. Add exponential backoff to `SidecarSupervisor`: `backoff_duration()` returns 1s, 2s, 4s... capped at 30s
2. Extract spawn logic into standalone `spawn_child()` function (not method) for reuse
3. Spawn watchdog thread in `spawn()`:
   - Every 10s: check `child.try_wait()` for exit
   - On exit: call `supervisor.record_crash()`, check `should_restart()`
   - If should restart: wait backoff, respawn via `spawn_child()`
4. Add `restart_tx: Sender<()>` channel to signal watchdog shutdown
5. In `kill()`: send shutdown signal to watchdog, then kill child
6. Add `Clone` impl to `SidecarSupervisor` (already uses Arc internally)

**Tests:** Backoff increases correctly, caps at 30s. Integration test (ignored): kill child, verify auto-restart.

**Dependencies:** Task 2.1 (needs PendingRequestTracker cleanup on restart)

---

### Task 2.3: Health Check Ping/Pong (5h)

**Files:** `src-tauri/src/bridge.rs`, `src-tauri/src/commands/agent.rs`, `src-tauri/src/types/agent.rs`

**Steps:**
1. Add `last_pong: Arc<Mutex<Option<Instant>>>` to `SidecarBridge`
2. Add `ping()` method: send `"ping"` JSON-RPC request, update `last_pong` on success
3. Add `is_healthy(max_silence: Duration)` method
4. Spawn health checker thread in `spawn()`: every 30s ping, mark crashed after 3 missed pongs (90s)
5. Add `AgentState::Unhealthy` variant for UI display
6. Agent already handles `"ping"` (returns `{ status: "ok", timestamp }`) — no agent-side changes

**Tests:** `is_healthy` returns false after max_silence, true within window.

**Dependencies:** Task 2.1 (needs real send_request for ping)

---

### Task 2.4: OS Keychain Credential Storage (6h)

**New files:** `src-tauri/src/keychain.rs`
**Files:** `src-tauri/Cargo.toml`, `src-tauri/src/lib.rs`, `src-tauri/src/commands/credentials.rs`

**Steps:**
1. Add `keyring = "2.3"` to Cargo.toml
2. Create `keychain.rs`: `keychain_set(mode, creds)`, `keychain_get(mode)`, `keychain_delete(mode)`, `keychain_exists(mode)`
   - Service name: `"dev.finwatch"`, key: `"alpaca_{mode}"`
   - Serialize credentials as JSON string
3. Update `credentials_set` command to write to keychain instead of SQLite
4. Update `credentials_get` to read from keychain (still mask secret in response)
5. Create `migrate_db_to_keychain(pool, mode)`: read from DB → write to keychain → delete from DB
6. Call migration on app startup in `lib.rs` (idempotent, `.ok()` to ignore errors)
7. Update `agent.rs` credential resolution to use keychain functions

**Tests:** Set+get roundtrip, get returns None when empty, delete removes entry, migration transfers data.

**Risks:** Keychain access may fail in CI — mark tests `#[ignore]`.

---

### Week 2 Dependency Graph
```
Task 2.1 (JSON-RPC tracking) ──┬──► Task 2.2 (Watchdog)
                                └──► Task 2.3 (Health check)
Task 2.4 (Keychain) ──────────────► (independent)
```

---

## Week 3: Intelligence Leap (~32 hours)

### Task 3.1: Wire Tool Use in LLM Providers (8h)

**New files:** `agent/src/tools/default-tools.ts`, `agent/src/tools/tool-executor.ts`
**Files:** `shared/src/provider.ts`, `agent/src/providers/anthropic-provider.ts`, `agent/src/providers/openrouter-provider.ts`, `agent/src/analysis/cycle-runner.ts`, `agent/src/orchestrator.ts`

**Steps:**
1. Add `tool_use` event to `StreamEvent` union: `{ type: "tool_use"; id: string; name: string; input: Record<string, unknown> }`
2. Anthropic: handle `content_block_start` with `type: "tool_use"`, yield event
3. OpenRouter: accumulate `delta.tool_calls[0].function.arguments`, yield on `finish_reason === "tool_calls"`
4. Create `ToolExecutor` class: consumes events, executes tool_use via `ToolRegistry.execute()`
5. Register default tools: `search_memory`, `get_historical_data` (placeholder handlers)
6. Integrate into `CycleRunner`: if `toolRegistry` provided, pass `tools` to `createMessage()`, execute tool results

**Note:** Multi-turn tool use (inject result → re-invoke LLM) deferred to Phase 4. Week 3 = single-round execution.

**Tests:** Provider emits tool_use events, ToolExecutor collects and executes, CycleRunner passes tools.

---

### Task 3.2: Fix Memory Embeddings (6h)

**New files:** `agent/src/memory/memory-manager.ts`, `agent/src/memory/backfill-embeddings.ts`
**Files:** `agent/src/memory/semantic-store.ts`, `agent/src/orchestrator.ts`

Currently `SemanticStore.flush()` stores `embedding=NULL`. The embedding pipeline exists but is disconnected.

**Steps:**
1. Add optional `EmbeddingService` to `SemanticStore` constructor
2. In `flush()`, fire-and-forget `generateAndStoreEmbedding(id, text)` — async, don't block
3. `generateAndStoreEmbedding`: call `embeddingService.embed(text)`, convert to Float32Array buffer, `UPDATE entries SET embedding=? WHERE id=?`
4. Create `backfillEmbeddings(db, service)`: SELECT where embedding IS NULL, batch embed+update with 500ms delays
5. Call backfill once at agent startup (if OpenAI key available)
6. Wire into Orchestrator: instantiate `EmbeddingService` if `OPENAI_API_KEY` set, pass to SemanticStore
7. Integrate hybrid search into `CycleRunner`: before building prompt, search memory for context

**Impact:** Unlocks vector similarity search, episodic recall, and context-enriched prompts.

**Tests:** flush generates embeddings (mock service), VectorStore.search returns results, backfill updates NULL rows.

---

### Task 3.3: Momentum/Mean-Reversion Classifier (10h)

**New files:** `agent/src/analysis/indicators.ts`, `agent/src/analysis/regime-classifier.ts`
**Files:** `agent/src/analysis/pre-screener.ts`, `agent/src/analysis/prompt-builder.ts`

**Steps:**
1. Implement technical indicators:
   - **RSI (14-period):** Smoothed relative strength using Wilder's method
   - **MACD (12,26,9):** EMA difference + signal line + histogram
   - **ATR (14-period):** True range with Wilder smoothing
2. Create `classifyRegime(indicators)`: returns `"momentum" | "mean-reversion" | "neutral" | "unknown"`
   - Momentum: RSI > 60 or < 40, MACD histogram > 0
   - Mean-reversion: RSI 45-55, MACD near zero
3. Extend `ScoredTick` with `regime?: Regime` and `indicators?` fields
4. In `preScreenBatch()`: group ticks by symbol, compute indicators from price history, classify regime
5. In `prompt-builder.ts formatTick()`: include regime in tick output

**Requirements:** Needs 26+ ticks per symbol for MACD. If insufficient history, regime = "unknown".

**Tests:** RSI on constant prices → 50, rising → >50. MACD histogram sign. ATR with known ranges. Regime classification logic.

---

### Task 3.4: Cross-Asset Correlation Detector (8h)

**New files:** `agent/src/analysis/correlation.ts`, `agent/src/analysis/correlation-detector.ts`
**Files:** `agent/src/analysis/prompt-builder.ts`, `agent/src/orchestrator.ts`

**Steps:**
1. Implement `pearsonCorrelation(x[], y[])`: standard formula
2. Create `CorrelationDetector` class:
   - `computeCorrelations(ticks)`: group by symbol, compute returns, pairwise Pearson on 30-tick window
   - Track historical correlations via EMA (0.95 * old + 0.05 * new)
   - Return `CorrelationPair[]` sorted by deviation
3. `detectBreakdowns(pairs, threshold=0.3)`: filter high-deviation pairs
4. Integrate into pre-screening: compute correlations before analysis cycle
5. Surface in prompt: "Correlation Breakdowns" section with pair details
6. Store learned correlations in `DomainCorrelation` table (existing schema)

**Requirements:** Needs 10+ overlapping ticks per symbol pair. O(n^2) pairs — limit to top 50.

**Tests:** Perfect positive/negative/zero correlation. Breakdown detection. EMA update.

---

### Week 3 Implementation Order
1. Task 3.1 (Tool use) — foundational, enables future multi-turn
2. Task 3.2 (Embeddings) — foundational, enables semantic recall
3. Task 3.3 (Indicators) — independent, enriches pre-screener
4. Task 3.4 (Correlations) — independent, enriches prompts

---

## Week 4: Trading Hub + Charting (~12 hours)

### Task 4.1: Build Trading Hub Page (4h)

**New files:** `src/pages/TradingHub.tsx`, `src/components/PositionsTable.tsx`, `src/components/TradeSuggestions.tsx`, `src/components/TradeHistory.tsx`, `src/components/RiskMetrics.tsx`, `src/components/KillSwitch.tsx`
**Files:** `src/App.tsx`, `src/components/Sidebar.tsx`, `src/hooks/use-agent-events.ts`

The `trading-slice` already has full state (suggestions, positions, history, mode, killSwitch). This task creates the UI.

**Layout:**
```
┌──────────────────────────────────────────┐
│ TRADING HUB    [PAPER]    [KILL SWITCH]  │
├──────────────────────────────────────────┤
│ Risk Metrics (2x2 grid)                  │
│  Total Exposure | Unrealized P&L         │
│  Largest Position | Open Positions       │
├──────────────────────────────────────────┤
│ ▼ Trade Suggestions (pending)            │
│  AAPL BUY 10 | Confidence 0.85          │
│  [APPROVE] [DISMISS]                     │
├──────────────────────────────────────────┤
│ Open Positions (sortable table)          │
│  Symbol | Qty | Entry | Current | P&L    │
├──────────────────────────────────────────┤
│ ▼ Trade History (sortable, filterable)   │
│  Time | Symbol | Side | Outcome          │
└──────────────────────────────────────────┘
```

**Steps:**
1. Add "Trading" tab to Sidebar (icon: ⚡)
2. Wire trading event listeners in `use-agent-events.ts` (`trade:suggestion`, `trade:executed`, `portfolio:update`)
3. Create components: KillSwitch, RiskMetrics, PositionsTable, TradeSuggestions, TradeHistory
4. Create TradingHub page composing all components
5. Wire `invoke()` calls: `trading_approve`, `trading_dismiss`, `trading_kill_switch`
6. Add to App.tsx routing

**Tests:** Render all sections, empty states, approve/dismiss button clicks, kill switch toggle.

---

### Task 4.2: TradingView Lightweight Charts (3h)

**New files:** `src/components/PriceChart.tsx`, `src/hooks/use-price-chart.ts`
**Files:** `package.json`, `src/pages/Dashboard.tsx`

**Steps:**
1. Install `lightweight-charts@^4.2.0`
2. Create `usePriceChart` hook: lifecycle management (create/update/destroy chart)
3. Create `PriceChart` component:
   - Theme: `background: #0a0a0a`, `grid: #222222`, `text: #666666`, `line: #00ff88`
   - Symbol selector dropdown
   - Real-time updates via `series.update()` on new ticks
   - ResizeObserver for responsive sizing
4. Add chart view toggle to Dashboard
5. Optional: volume histogram series overlay

**Tests:** Chart creation on mount, data update, cleanup on unmount (mock lightweight-charts).

---

### Task 4.3: Dashboard Sparklines + Anomaly Timeline (2.5h)

**New files:** `src/components/Sparkline.tsx`, `src/components/AnomalyTimeline.tsx`
**Files:** `src/pages/Dashboard.tsx`, `src/pages/AnomalyFeed.tsx`

**Steps:**
1. Create `Sparkline` SVG component (same pattern as BacktestResults equity curve):
   - Props: `data: number[]`, `width`, `height`, `color`
   - Scale to fit, render polyline
2. Add sparklines to Dashboard symbol cards (last 20 ticks, price metric)
3. Create `AnomalyTimeline`: horizontal SVG timeline with severity-colored dots
4. Add "List View / Timeline View" toggle to AnomalyFeed header

**Tests:** Sparkline renders with data, AnomalyTimeline positions dots correctly, empty states.

---

### Task 4.4: Desktop Notifications with Actions (2.5h)

**New files:** `src/utils/notifications.ts`
**Files:** `src-tauri/Cargo.toml`, `src-tauri/src/lib.rs`, `src-tauri/capabilities/default.json`, `package.json`, `src/hooks/use-agent-events.ts`

**Steps:**
1. Install `tauri-plugin-notification` (Rust + JS)
2. Register plugin in `lib.rs`, add permissions to capabilities
3. Create notification helpers: `notifyAnomaly()`, `notifyTradeSuggestion()`, `notifyTradeExecuted()`
4. Handle notification actions (approve/dismiss) via `onAction` listener
5. Trigger notifications in `use-agent-events.ts` (anomaly severity >= high, all trade suggestions)
6. Add notification preferences to Settings (enable/disable, severity threshold)
7. Debounce: max 1 anomaly notification per 10 seconds

**Tests:** Notification formatting, action handler, debounce logic (mock Tauri plugin).

---

### Week 4 Implementation Order
1. Task 4.1 (Trading Hub) — core UI feature
2. Task 4.2 (Charts) — highest visual impact
3. Task 4.3 (Sparklines + Timeline) — polish
4. Task 4.4 (Notifications) — cross-cutting

---

## New Files Summary

| Week | New Files |
|------|-----------|
| 1 | `src/components/Toast.tsx`, `src/utils/format.ts` |
| 2 | `src-tauri/src/bridge_pending.rs`, `src-tauri/src/keychain.rs` |
| 3 | `agent/src/analysis/indicators.ts`, `agent/src/analysis/regime-classifier.ts`, `agent/src/analysis/correlation.ts`, `agent/src/analysis/correlation-detector.ts`, `agent/src/tools/default-tools.ts`, `agent/src/tools/tool-executor.ts`, `agent/src/memory/memory-manager.ts`, `agent/src/memory/backfill-embeddings.ts` |
| 4 | `src/pages/TradingHub.tsx`, `src/components/PositionsTable.tsx`, `src/components/TradeSuggestions.tsx`, `src/components/TradeHistory.tsx`, `src/components/RiskMetrics.tsx`, `src/components/KillSwitch.tsx`, `src/components/PriceChart.tsx`, `src/components/Sparkline.tsx`, `src/components/AnomalyTimeline.tsx`, `src/hooks/use-price-chart.ts`, `src/utils/notifications.ts` |

## Dependencies Between Weeks

```
Week 1 (Foundation) ──► Week 2 (Sidecar + Security)
                    ──► Week 3 (Intelligence)
                    ──► Week 4 (Trading + Charts)

Week 2.1 (JSON-RPC) ──► Week 2.2 (Watchdog)
                     ──► Week 2.3 (Health check)

Week 2.4 (Keychain) ──► (independent)
Week 3.* ──► (all independent of each other)
Week 4.1 (Trading Hub) ──► Week 4.4 (Notifications use trading state)
```

Week 1 should complete first. Weeks 2-4 can overlap with parallel engineers.
